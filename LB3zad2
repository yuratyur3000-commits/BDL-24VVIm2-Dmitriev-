# Задание 2: Классификация цветков ириса (версия с загрузкой из файла в рабочей директории Spyder)

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import sys

print("=" * 60)
print("КЛАССИФИКАЦИЯ ЦВЕТКОВ ИРИСА С ИСПОЛЬЗОВАНИЕМ PyTorch")
print("=" * 60)

# 1. Загрузка и подготовка данных
print("\n1. ЗАГРУЗКА И ПОДГОТОВКА ДАННЫХ:")

# Определяем текущую рабочую директорию Spyder
current_working_dir = r'C:\Users\Юрий\Documents\ИТК\ПГУ\Магистрат\ВТ\2КУРС\Нейронные\2_Основы python_обучение нейрона-20250918T141315Z-1-001\2_Основы python_обучение нейрона'
file_name = 'data.csv'
file_path = os.path.join(current_working_dir, file_name)

print(f"  Ищу файл: {file_name}")
print(f"  В директории: {current_working_dir}")
print(f"  Полный путь: {file_path}")

# Проверяем существование файла
if not os.path.exists(file_path):
    print(f"\n✗ ОШИБКА: Файл '{file_name}' не найден в рабочей директории!")
    print(f"  Директория: {current_working_dir}")
    print(f"  Проверьте, что файл находится в этой папке.")
    
    # Показываем содержимое директории
    print(f"\n  Содержимое директории {current_working_dir}:")
    try:
        files = os.listdir(current_working_dir)
        if files:
            csv_files = [f for f in files if f.lower().endswith('.csv')]
            print(f"  Всего файлов: {len(files)}")
            print(f"  CSV файлы: {csv_files if csv_files else 'не найдены'}")
            print("\n  Все файлы:")
            for i, file in enumerate(files[:20]):  # показываем первые 20 файлов
                print(f"    {i+1:3d}. {file}")
            if len(files) > 20:
                print(f"    ... и ещё {len(files) - 20} файлов")
        else:
            print("  Директория пуста")
    except Exception as e:
        print(f"  Не удалось прочитать директорию: {e}")
    
    print("\n" + "=" * 60)
    print("ПРОГРАММА ОСТАНОВЛЕНА!")
    print("Поместите файл data.csv в папку:")
    print(f"{current_working_dir}")
    print("=" * 60)
    
    # Останавливаем программу
    sys.exit(1)

# Загружаем файл
try:
    print(f"\n✓ Файл найден! Загружаю данные...")
    df = pd.read_csv(file_path)
    print(f"  Файл успешно загружен")
    print(f"  Размер данных: {df.shape}")
    
    # Показываем информацию о данных
    print("\n  Информация о данных:")
    print(df.info())
    
    print("\n  Первые 5 строк данных:")
    print(df.head())
    
    print(f"\n  Столбцы в файле ({len(df.columns)}):")
    for i, col in enumerate(df.columns):
        print(f"    {i+1:2d}. '{col}' (тип: {df[col].dtype}, уникальных: {df[col].nunique()})")
    
except Exception as e:
    print(f"\n✗ ОШИБКА ПРИ ЗАГРУЗКЕ ФАЙЛА: {e}")
    print("  Проверьте формат файла (должен быть CSV)")
    sys.exit(1)

# 2. Анализ структуры данных и подготовка
print("\n2. АНАЛИЗ СТРУКТУРЫ ДАННЫХ:")

# Определяем, какие столбцы являются признаками, а какие - целевой переменной
# Для датасета ирисов обычно: 4 числовых признака + 1 целевая переменная (класс)

# Ищем числовые и строковые столбцы
numeric_cols = []
string_cols = []

for col in df.columns:
    if pd.api.types.is_numeric_dtype(df[col]):
        numeric_cols.append(col)
    else:
        string_cols.append(col)

print(f"  Числовые столбцы ({len(numeric_cols)}): {numeric_cols}")
print(f"  Строковые столбцы ({len(string_cols)}): {string_cols}")

# Определяем стратегию подготовки данных
if len(numeric_cols) >= 4 and len(string_cols) == 1:
    # Идеальный случай: 4+ числовых признаков и 1 строковый (метки классов)
    X_columns = numeric_cols[:4]  # берем первые 4 числовых столбца
    y_column = string_cols[0]     # строковый столбец как целевая переменная
    
    print(f"\n  Использую стратегию 1:")
    print(f"    Признаки (X): {X_columns}")
    print(f"    Целевая переменная (y): {y_column}")
    
elif len(df.columns) == 5:
    # 5 столбцов - предположим, что последний это целевая переменная
    X_columns = df.columns[:4].tolist()
    y_column = df.columns[4]
    
    print(f"\n  Использую стратегию 2 (5 столбцов):")
    print(f"    Признаки (X): {X_columns}")
    print(f"    Целевая переменная (y): {y_column}")
    
elif len(numeric_cols) >= 4:
    # Только числовые столбцы, возможно последний - целевая переменная
    X_columns = numeric_cols[:4]
    y_column = numeric_cols[-1] if len(numeric_cols) > 4 else numeric_cols[-1]
    
    print(f"\n  Использую стратегию 3 (только числовые):")
    print(f"    Признаки (X): {X_columns}")
    print(f"    Целевая переменная (y): {y_column}")
    
else:
    print(f"\n✗ ОШИБКА: Не могу определить структуру данных!")
    print(f"  Требуется: 4+ признаков и 1 целевая переменная")
    print(f"  В файле: {len(df.columns)} столбцов")
    print(f"  Числовых: {len(numeric_cols)}, Строковых: {len(string_cols)}")
    sys.exit(1)

# Подготавливаем данные
try:
    X = df[X_columns].values
    y_original = df[y_column].values
    
    print(f"\n  Размерность признаков X: {X.shape}")
    print(f"  Тип целевой переменной: {type(y_original[0])}")
    
    # Преобразуем метки классов в числовой формат, если они строковые
    if isinstance(y_original[0], str):
        unique_classes = np.unique(y_original)
        class_mapping = {cls: i for i, cls in enumerate(unique_classes)}
        y = np.array([class_mapping[val] for val in y_original])
        target_names = unique_classes.tolist()
        
        print(f"\n  Строковые метки преобразованы в числовые:")
        for i, cls in enumerate(unique_classes):
            count = np.sum(y_original == cls)
            print(f"    '{cls}' → {i} ({count} примеров)")
    else:
        y = y_original.astype(int)
        unique_classes = np.unique(y)
        target_names = [f'Класс {i}' for i in unique_classes]
        
        print(f"\n  Числовые метки классов:")
        for cls in unique_classes:
            count = np.sum(y == cls)
            print(f"    Класс {cls}: {count} примеров")
    
    print(f"\n  Итоговая размерность:")
    print(f"    X: {X.shape} ({len(X_columns)} признаков: {', '.join(X_columns)})")
    print(f"    y: {y.shape} ({len(unique_classes)} классов)")
    
except Exception as e:
    print(f"\n✗ ОШИБКА ПРИ ПОДГОТОВКЕ ДАННЫХ: {e}")
    sys.exit(1)

# 3. Разделение данных на обучающую и тестовую выборки
print("\n3. РАЗДЕЛЕНИЕ ДАННЫХ:")

# Вручную разделяем данные (80% обучение, 20% тест)
np.random.seed(42)
indices = np.arange(len(X))
np.random.shuffle(indices)

split_idx = int(0.8 * len(X))
train_indices = indices[:split_idx]
test_indices = indices[split_idx:]

X_train = X[train_indices]
X_test = X[test_indices]
y_train = y[train_indices]
y_test = y[test_indices]

print(f"  Обучающая выборка: {X_train.shape[0]} примеров")
print(f"  Тестовая выборка: {X_test.shape[0]} примеров")

# Нормализуем данные
X_train_mean = X_train.mean(axis=0)
X_train_std = X_train.std(axis=0)
X_test_mean = X_test.mean(axis=0)
X_test_std = X_test.std(axis=0)

# Избегаем деления на ноль
X_train_std = np.where(X_train_std == 0, 1, X_train_std)
X_test_std = np.where(X_test_std == 0, 1, X_test_std)

X_train_scaled = (X_train - X_train_mean) / X_train_std
X_test_scaled = (X_test - X_test_mean) / X_test_std

# Преобразуем в тензоры PyTorch
X_train_tensor = torch.FloatTensor(X_train_scaled)
X_test_tensor = torch.FloatTensor(X_test_scaled)
y_train_tensor = torch.LongTensor(y_train)
y_test_tensor = torch.LongTensor(y_test)

print(f"  Тип X_train_tensor: {X_train_tensor.dtype}, размер: {X_train_tensor.shape}")
print(f"  Тип y_train_tensor: {y_train_tensor.dtype}, размер: {y_train_tensor.shape}")

# 4. Создание модели нейронной сети
print("\n4. СОЗДАНИЕ МОДЕЛИ НЕЙРОННОЙ СЕТИ:")

class IrisClassifier(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(IrisClassifier, self).__init__()
        
        # Определяем слои сети
        self.layer1 = nn.Linear(input_size, hidden_size)
        self.layer2 = nn.Linear(hidden_size, hidden_size)
        self.layer3 = nn.Linear(hidden_size, num_classes)
        
        # Функции активации
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(p=0.1)
        
    def forward(self, x):
        x = self.layer1(x)
        x = self.relu(x)
        x = self.dropout(x)
        
        x = self.layer2(x)
        x = self.relu(x)
        x = self.dropout(x)
        
        x = self.layer3(x)
        return x

# Определяем параметры модели
input_size = X_train.shape[1]
hidden_size = 10
num_classes = len(unique_classes)

model = IrisClassifier(input_size=input_size, hidden_size=hidden_size, num_classes=num_classes)
print("   Архитектура модели:")
print(model)
print(f"\n   Количество параметров модели: {sum(p.numel() for p in model.parameters())}")

# 5. Определение функции потерь и оптимизатора
print("\n5. ОПРЕДЕЛЕНИЕ ФУНКЦИИ ПОТЕРЬ И ОПТИМИЗАТОРА:")

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.01)

print(f"   Функция потерь: {criterion}")
print(f"   Оптимизатор: Adam с learning rate = 0.01")

# 6. Обучение модели
print("\n6. ОБУЧЕНИЕ МОДЕЛИ:")

num_epochs = 200
batch_size = 16
train_losses = []
test_accuracies = []

print(f"   Количество эпох: {num_epochs}")
print(f"   Размер пакета: {batch_size}")

for epoch in range(num_epochs):
    # Перемешиваем данные каждый эпох
    indices = torch.randperm(X_train_tensor.size(0))
    X_shuffled = X_train_tensor[indices]
    y_shuffled = y_train_tensor[indices]
    
    epoch_loss = 0
    num_batches = 0
    
    # Обучение пакетами (mini-batch)
    for i in range(0, len(X_train_tensor), batch_size):
        batch_X = X_shuffled[i:i+batch_size]
        batch_y = y_shuffled[i:i+batch_size]
        
        # Прямой проход
        outputs = model(batch_X)
        loss = criterion(outputs, batch_y)
        
        # Обратный проход и оптимизация
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        epoch_loss += loss.item()
        num_batches += 1
    
    # Средняя потеря за эпоху
    avg_loss = epoch_loss / num_batches
    train_losses.append(avg_loss)
    
    # Оценка на тестовых данных каждые 20 эпох
    if (epoch + 1) % 20 == 0 or epoch == 0:
        with torch.no_grad():
            test_outputs = model(X_test_tensor)
            _, predicted = torch.max(test_outputs, 1)
            accuracy = (predicted == y_test_tensor).float().mean()
            test_accuracies.append(accuracy.item())
            
        print(f"   Эпоха [{epoch+1:3d}/{num_epochs}], "
              f"Потеря: {avg_loss:.4f}, "
              f"Точность на тесте: {accuracy:.4f}")

# 7. Оценка модели
print("\n7. ОЦЕНКА МОДЕЛИ:")

with torch.no_grad():
    model.eval()
    
    test_outputs = model(X_test_tensor)
    _, predicted = torch.max(test_outputs, 1)
    
    accuracy = (predicted == y_test_tensor).float().mean()
    print(f"   Финальная точность на тестовых данных: {accuracy:.4f}")
    
    # Матрица ошибок
    cm = np.zeros((num_classes, num_classes), dtype=int)
    for i in range(len(y_test)):
        true_class = y_test[i]
        pred_class = predicted[i].item()
        cm[true_class][pred_class] += 1
    
    print(f"\n   Матрица ошибок:")
    header = " " * 15 + "Предсказано →"
    print(f"   {header}")
    print("   " + " " * 15 + " ".join([f"{i:^3}" for i in range(num_classes)]))
    print("   " + "Истинно ↓" + " " * 7 + "-" * (num_classes * 4))
    
    for i in range(num_classes):
        if i < len(target_names):
            row_label = target_names[i][:12]
        else:
            row_label = f"Класс {i}"
        row_values = " ".join([f"{cm[i][j]:3}" for j in range(num_classes)])
        print(f"   {row_label:12} | {row_values}")

# 8. Визуализация
print("\n8. ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ:")

fig, axes = plt.subplots(1, 2, figsize=(12, 4))

# График функции потерь
axes[0].plot(range(1, num_epochs + 1), train_losses, 'b-', linewidth=2)
axes[0].set_xlabel('Эпоха')
axes[0].set_ylabel('Потеря')
axes[0].set_title('Функция потерь во время обучения')
axes[0].grid(True, alpha=0.3)

# График точности
epochs_to_plot = list(range(0, num_epochs, 20)) + [num_epochs - 1]
if num_epochs - 1 not in epochs_to_plot:
    epochs_to_plot.append(num_epochs - 1)
accuracy_epochs = [i for i in epochs_to_plot if i < len(test_accuracies)]
axes[1].plot([e+1 for e in accuracy_epochs], 
             [test_accuracies[i] for i in accuracy_epochs], 
             'r-o', linewidth=2)
axes[1].set_xlabel('Эпоха')
axes[1].set_ylabel('Точность')
axes[1].set_title('Точность на тестовых данных')
axes[1].set_ylim([0, 1.1])
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# 9. Демонстрация работы модели
print("\n9. ДЕМОНСТРАЦИЯ РАБОТЫ МОДЕЛИ:")

print(f"\n   Примеры предсказаний для тестовых данных:")
print("   " + "-" * 90)
header = "   |"
for col in X_columns:
    header += f" {col[:10]:10} |"
header += " Предсказанный класс | Истинный класс |"
print(header)
print("   " + "-" * 90)

# Несколько примеров
sample_indices = list(range(min(5, len(X_test))))
for idx in sample_indices:
    sample = X_test_tensor[idx:idx+1]
    with torch.no_grad():
        output = model(sample)
        _, predicted_class = torch.max(output, 1)
    
    original_features = X_test[idx]
    
    if predicted_class.item() < len(target_names):
        predicted_name = target_names[predicted_class.item()]
    else:
        predicted_name = f"Класс {predicted_class.item()}"
    
    if y_test[idx] < len(target_names):
        true_name = target_names[y_test[idx]]
    else:
        true_name = f"Класс {y_test[idx]}"
    
    row = "   |"
    for feat_value in original_features:
        row += f" {feat_value:10.2f} |"
    row += f" {predicted_name:18} | {true_name:15} |"
    print(row)

print("   " + "-" * 90)
