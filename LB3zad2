import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np

print("=" * 60)
print("КЛАССИФИКАЦИЯ НА ДАННЫХ")
print("=" * 60)

# 1. Создаем данные ирисов
print("\n1. СОЗДАНИЕ ДАННЫХ:")

np.random.seed(42)
torch.manual_seed(42)

# Создаем 150 примеров с 4 признаками
n_samples = 150
n_features = 4
n_classes = 3

# Генерируем данные для 3 классов
X = []
y = []

# Класс 0
for _ in range(50):
    X.append([4.5 + np.random.randn()*0.5, 3.0 + np.random.randn()*0.3, 
              1.5 + np.random.randn()*0.2, 0.2 + np.random.randn()*0.1])
    y.append(0)

# Класс 1
for _ in range(50):
    X.append([6.0 + np.random.randn()*0.6, 2.7 + np.random.randn()*0.3, 
              4.5 + np.random.randn()*0.4, 1.5 + np.random.randn()*0.2])
    y.append(1)

# Класс 2
for _ in range(50):
    X.append([6.5 + np.random.randn()*0.7, 3.0 + np.random.randn()*0.3, 
              5.8 + np.random.randn()*0.5, 2.2 + np.random.randn()*0.3])
    y.append(2)

X = np.array(X, dtype=np.float32)
y = np.array(y, dtype=np.int64)

print(f"   Создано {len(X)} примеров")
print(f"   Размерность данных: {X.shape}")
print(f"   Количество классов: {len(np.unique(y))}")

# Нормализуем данные вручную
X_mean = X.mean(axis=0)
X_std = X.std(axis=0)
X_normalized = (X - X_mean) / X_std

# Разделяем на обучающую и тестовую выборки
split_idx = int(0.8 * len(X))
X_train = X_normalized[:split_idx]
X_test = X_normalized[split_idx:]
y_train = y[:split_idx]
y_test = y[split_idx:]

print(f"\n   Обучающая выборка: {X_train.shape[0]} примеров")
print(f"   Тестовая выборка: {X_test.shape[0]} примеров")

# Преобразуем в тензоры PyTorch
X_train_tensor = torch.FloatTensor(X_train)
X_test_tensor = torch.FloatTensor(X_test)
y_train_tensor = torch.LongTensor(y_train)
y_test_tensor = torch.LongTensor(y_test)

# 2. Создание модели
print("\n2. СОЗДАНИЕ МОДЕЛИ НЕЙРОННОЙ СЕТИ:")

class SimpleClassifier(nn.Module):
    def __init__(self, input_size=4, hidden_size=10, num_classes=3):
        super(SimpleClassifier, self).__init__()
        self.layer1 = nn.Linear(input_size, hidden_size)
        self.layer2 = nn.Linear(hidden_size, hidden_size)
        self.layer3 = nn.Linear(hidden_size, num_classes)
        self.relu = nn.ReLU()
        
    def forward(self, x):
        x = self.relu(self.layer1(x))
        x = self.relu(self.layer2(x))
        x = self.layer3(x)
        return x

model = SimpleClassifier(input_size=4, hidden_size=10, num_classes=3)
print("   Модель создана успешно!")
print(f"   Архитектура: {model}")

# 3. Обучение модели
print("\n3. ОБУЧЕНИЕ МОДЕЛИ:")

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.01)

num_epochs = 100
for epoch in range(num_epochs):
    # Прямой проход
    outputs = model(X_train_tensor)
    loss = criterion(outputs, y_train_tensor)
    
    # Обратный проход и оптимизация
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    if (epoch + 1) % 20 == 0:
        # Оценка на тестовых данных
        with torch.no_grad():
            test_outputs = model(X_test_tensor)
            _, predicted = torch.max(test_outputs, 1)
            accuracy = (predicted == y_test_tensor).float().mean()
            
        print(f"   Эпоха [{epoch+1:3d}/{num_epochs}], "
              f"Потеря: {loss.item():.4f}, "
              f"Точность: {accuracy:.4f}")

# 4. Финальная оценка
print("\n4. ФИНАЛЬНАЯ ОЦЕНКА:")

with torch.no_grad():
    model.eval()
    test_outputs = model(X_test_tensor)
    _, predicted = torch.max(test_outputs, 1)
    accuracy = (predicted == y_test_tensor).float().mean()
    
    print(f"   Точность на тестовых данных: {accuracy:.4f}")
    
    # Подсчет правильных предсказаний по классам
    print("\n   Правильные предсказания по классам:")
    for class_idx in range(3):
        class_mask = y_test == class_idx
        if class_mask.any():
            class_accuracy = (predicted[class_mask] == y_test_tensor[class_mask]).float().mean()
            print(f"   Класс {class_idx}: {class_accuracy:.2%}")

print("\n" + "=" * 60)
print("ОБУЧЕНИЕ ЗАВЕРШЕНО!")
print("=" * 60)
